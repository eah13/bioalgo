%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\documentclass[12pt]{amsart}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{geometry}            
\usepackage{array}
\usepackage{tikz}
\usepackage{afterpage}
\usetikzlibrary{calc,arrows}
\usepackage{xskak}
\usepackage{listings}
\lstset{language=Octave,
  basicstyle=\footnotesize,tabsize=3,
commentstyle=\color{blue},
morecomment=[l]{\#},
numbers=left,   
numberstyle=\footnotesize,      
stepnumber=1}
\geometry{letterpaper}  
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath} 
\usepackage{epstopdf}
\usepackage{fontspec,xltxtra,xunicode}
\defaultfontfeatures{Mapping=tex-text}
\setromanfont[Mapping=tex-text]{Hoefler Text}
\setsansfont[Scale=MatchLowercase,Mapping=tex-text]{Gill Sans}
\setmonofont[Scale=MatchLowercase]{Andale Mono}

\newcommand{\tikzmark}[1]{%
  \tikz[overlay,remember picture] \node (#1) {};}

\title{COMP 555 Problem Set 2}
\author{Elliott Hauser}
\date{October 11, 2012}                                           
\begin{document}


\maketitle
%number of coins d, denomination of coins c, M amount to be rendered in coins
\section{}
\paragraph{1a.}  I can find only one condition that is necessary and sufficient to ensure that a solution to the change problem exists:
%a necessary and sufficient condition on c so that the change problem always has a solution
\begin{equation*}
\exists c_i = 1
\end{equation*}
This states that one denomination $c_i$ always be equal to one.\begin{footnote}{Another condition, $\exists c_i = M$ is sufficient but not necessary.  This is also a bit of a cheat and will in practice rarely occur (i.e. the denomination of money is not alterable, and there is d/M probability that this condition would be satisfied by a random set of denominations, assuming M$\geq$max$(c)$)}\end{footnote}  This is both sufficient because, for any integer $M, M$ mod $c_i$ = 0 when either condition holds, meaning that some combination of coins will always exist that adds up to $M$ with no remainder.  It is necessary because in the absence of $c_i=1$, $\exists M \mod c_i \neq$  0.\\

\paragraph{1b. and 1c}
%determine the approximation ratio of the greedy BetterChange also when c={25,20,10,5,1) and 0<M<100
The BetterChange algorithm in chapter 2 is given as:\\
BetterChange($M$,\textbf{c},$d$)
\begin{lstlisting}[mathescape=true]
$r \gets M$
for $k \gets 1$ to $d$
	$i_k \gets r/c_k$
	$r \gets r - c_k*i_k$
return($i_1,i_2,\cdots,i_d$)
\end{lstlisting}
The approximation ratio of this algorithm is defined as $\max\limits_{|\pi|=n}\frac{\mathcal{A}(\pi)}{OPT(\pi)}$, where $\mathcal{A}(\pi)=$ BetterChange($M$,\textbf{c},$d$).  In other words, this is the algorithm's worst performance compared to the optimal solution.  To start, we'll specify this ratio for $0 \leq M \leq 100$.  Since \textbf{c} and $d$ are held constant, we'll only use $M$ for $\pi$. The values of $M$ for which BetterChange is incorrect are shown here:\\
\begin{eqnarray*}
\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{\text{BetterChange}(M)}{OPT(M)}\\
 \\
0 \leq M \leq 100\\
\vdots\\
\text{for } M=40, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{3}{2}\\
\text{for } M=41, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{4}{3}\\
\text{for } M=42, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{5}{4}\\
\text{for } M=43, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{6}{5}\\
\text{for } M=44, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{7}{6}\\
\vdots\\
\text{for } M=65, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{4}{3}\\
\text{for } M=66, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{5}{4}\\
\text{for } M=67, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{6}{5}\\
\text{for } M=68, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{7}{6}\\
\text{for } M=69, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{8}{7}\\
\vdots\\
\text{for } M=90, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{5}{4}\\
\text{for } M=91, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{6}{5}\\
\text{for } M=92, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{7}{6}\\
\text{for } M=93, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{8}{7}\\
\text{for } M=94, \frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{9}{8}\\
\vdots\\
\end{eqnarray*}
So the approximation ratio for BetterChange where $0 \leq M \leq 100$ is $\max \begin{cases} \frac{3}{2}\\\frac{4}{3}\\\frac{5}{4}\\\end{cases}= 1.5$.  Can this result be generalized for all $M \geq 0$?

There is a pattern to the above.  In each of these cases, $M \geq 25$, and $15 \leq M\mod 25 < 20$.  Also, $\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{n+1}{n}$.  I believe this is because $((((40\% 25)\% 20)\%10)\% 5)=3$ and $40\% 20 = 2$; it is this portion of the formula that contributes the $+1$ to the numerator.  For $15 \leq M\mod 25 < 20$ and $\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{n+1}{n}$, 
\begin{equation*}
n=(M\% 20)+ (M\% 25 -15)
\end{equation*}yielding:
\begin{equation*}
\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{n+1}{n}=\frac{(M\% 20)+ (M\% 25 -15)+1}{(M\% 20) + (M\% 25 -15)}
\end{equation*}
This is a long way of saying that, for c=\{1,5,10,20,25\} the approximation ratio of BetterChange is 1.5 for any $M \geq 0$.  the difference between numerator and denominator will only ever be 1, and this fraction will be greatest for the smallest possible value of $n$.  Since $\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{n+1}{n}$ only holds for $M \geq 25$ and$15 \leq M\mod 25 \leq 19$, $M=40$ (i.e. $n=2$) yields the maximum value of this function, 1.5.\\
%determine the approximation ratio of the greedy BetterChange also when c={25,20,10,5,1) and 0<M

\paragraph{1d.}  If we'd like to estimate the maximum value of $\frac{\mathcal{A}(\pi)}{OPT(\pi)}$ for any set of denominations $c$, we'll have to generalize the fraction $\frac{n+1}{n}$ and state it in terms of c.

For c = \{1,5,10,20,25\} and $M \geq 25$ and$15 \leq M\mod 25 \leq 19$,
\begin{displaymath}
\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{n+i}{n}=\frac{2+1}{2}=1.5
\end{displaymath}

For another example $c=\{1,20,25\}$ and$M \geq 25$ and$15 \leq M\mod 25 < 20$, the same numbers hold.  This suggests that the formula can be stated in terms of $c_{\max}, c_{\max-1}$, and $c_1$.  

For $c=\{1,15,25\}$ and $M \geq 25$ and$5 \leq M\mod 25 \leq 14$, 
\begin{displaymath}
\frac{n+i}{n}=\frac{2+4}{2}=3.0
\end{displaymath}
%upperbound on approx ratio for arbitrary C, M\geq 0

It is somewhat difficult to see the connection here, but we can induce a formula that explains these and other outcomes.

In all cases, $n$ is the optimal number of coins.  For the purposes of determining a maximum, we can assume that this is the lowest possible number where BetterChange will produce a discrepancy, $n=2$, because this will maximize the fraction.  Next we need to determine when BetterChange will be incorrect.  This will be the case iff $\exists c_i > \frac{c_{\max}}{2}$.We'll first consider the simplest case where there is one $c_i > \frac{c_{\max}}{2}$.  In the two examples we've seen so far, $c_{\max}=25$ and $c_i = \{15,20\}$.

Next, we need to characterize the values of $M$ that will be erroneously predicted.  For
c = \{1,5,10,20,25\} and $M \geq 25$ and$15 \leq M\mod 25 < 20$.  How can we state these latter equations in terms of c?
\begin{alignat*}{2}
M \geq 25 &\equiv M\geq c_{\max}&\\
15 \leq M\mod 25 < 20&\equiv \big(2*c_{\max-1} -c_{max}\big) \leq M \mod c_{max} < c_{\max-1}
\end{alignat*}

With these equations in hand, the one remaining problem is to determine the value of $i$.  It's again difficult to see how, for $c=\{1,5,10,20,25\}$, $i=1$, while for $c=\{1,20,25\}$, $i=14$.  But upon closer inspection, it is clear that 
\begin{alignat*}{2}
i&=\text{BetterChange}\Big(((2*c_{\max-1} -c_{max}\big), c, d)-1
\end{alignat*}
In other words, the difference between twice $c_{\max-1}$ and $c_{\max}$ is run through the BetterChange algorithm, and the result is decremented by one.

We should now test this admittedly complex system of equations with a random c, chosen for its difficulty.  One feature of all of the cs evaluated so far is their common denominators.  So, for this test, I'll choose a c comprised entirely out of primes.
\begin{displaymath}
c=\{1,7,11\}\\
\end{displaymath}

Following the equations above, the errors in BetterChange should be given by\\
\begin{alignat*}{1}
\bigg[\big(2*c_{\max-1} -c_{max}\big) \leq M \mod c_{max} < c_{\max-1}\bigg]&=\bigg[\big(2*7 -11\big) \leq M \mod 11 < 7\bigg]\\
M_{\text{errors}}&=\{14,15,16,17,25,26,27,28\cdots\}
\end{alignat*}
So what is the approximation ratio in this case?
\begin{alignat*}{1}
\frac{\mathcal{A}(\pi)}{OPT(\pi)}&=\frac{n+i}{n}\\
i&=\text{BetterChange}\Big(((2*c_{\max-1} -c_{max}\big), c, d)-1\\
&=\text{BetterChange}\Big((3, \{1,7,11\}, 3)-1\\
&=2\\
&\therefore\\
\frac{n+i}{n}&=\frac{4}{2}\\
\end{alignat*}
Is this correct?  We can see that that for the first erroneous prediction, M=14, BetterChange would return one 11¢ coin and three 1¢ coins, whereas the optimal solution yields two 7¢ coins.\begin{footnote}{There is a problem with the formula as written, however.  It only is correct when $c_{\max-1}$ is the \textit{only} denomination greater than half of $c_{\max}$.  For $c=\{1,7,9,11\}$, our formula predicts an approximation ratio of $\frac{4}{2}$, as above.  But BetterChange$(18,c,d)$ returns two coins, an 11¢ and 7¢.  Our formula needs to be modified to include all denominations greater than half of $c_{\max}$.  Since this won't effect the approximation ratio (i.e. such cases are always less bad than the worst cases) we can ignore this and exclude possible $c$ where there is more than one denomination greater than half of $c_{\max}$.}\end{footnote}

So, to return to the question at hand, can we determine an upper bound on the approximation ratio?  There is no limit.  Because $\frac{\mathcal{A}(\pi)}{OPT(\pi)}=\frac{n+i}{n}$, we know that the ratio will vary with $i$.  As (erroneous) $c$ get larger and larger, this ratio increases as well.  For example, with $c=\{1,75,100\}$,
\begin{alignat*}{1}
\frac{\mathcal{A}(\pi)}{OPT(\pi)}&=\frac{n+i}{n}\\
i&=\text{BetterChange}\Big(((2*c_{\max-1} -c_{max}\big), c, d)-1\\
&=\text{BetterChange}\Big((2*75 -100, \{1,75,100\}, 3)-1\\
&=\text{BetterChange}\Big((50, \{1,75,100\}, 3)-1\\
&=50\\
&\therefore\\
\frac{n+i}{n}&=\frac{52}{2}=26.0\\
\end{alignat*}
 
 I have been unable to determine the particular relationship between the components of $c$ and the numerical ratio.  It seems that they could be related, but that this would need to involve recursion.

\clearpage
\section{} The steps to perform a reversal sort on a sequence $\pi$ are below.\begin{footnote}{I'm considering a string sorted when it is in either ascending or descending order.  Ascending order only would add one reversal each to the reversal sorts below}\end{footnote}\\
$\pi = 3 4 6 5 8 1 7 2$\\
BreakpointReversalSort($\pi$)
\begin{lstlisting}[mathescape=true]
$\underrightarrow{3 \text{ } 4}$ $ \underleftarrow{6\text{ } 5}$ $ \underleftarrow{8} \underleftarrow{1} \underleftarrow{7} \underleftarrow{2}$ b($\pi$)=5
$\underrightarrow{3 \text{ }4}$ $ \underleftarrow{6 \text{ }5}$ $ \underleftarrow{8 \text{ }7}$ $\underrightarrow{1\text{ } 2}$ b($\pi$)=3
$\underrightarrow{3 \text{ }4 \text{ }5\text{ }6}$ $ \underleftarrow{8 \text{ }7}$ $\underrightarrow{1\text{ } 2}$ b($\pi$)=2
$\underrightarrow{3 \text{ }4 \text{ }5\text{ }6 \text{ }7\text{ }8}$ $\underrightarrow{1\text{ } 2}$ b($\pi$)=1
$\underrightarrow{3 \text{ }4 \text{ }5\text{ }6 \text{ }7\text{ }8}$ $\underleftarrow{2\text{ } 1}$ b($\pi$)=1
$\underleftarrow{8 \text{ }7 \text{ }6\text{ }5 \text{ }4\text{ }3\text{ }2\text{ } 1}$ b($\pi$)=0
\end{lstlisting}
It seems there is a shorter method of achieving this sort:

OtherReversalSort($\pi$)
\begin{lstlisting}[mathescape=true]
$\underrightarrow{3 \text{ } 4}$ $ \underleftarrow{6\text{ } 5}$ $ \underleftarrow{8} \underleftarrow{1} \underleftarrow{7} \underleftarrow{2}$ b($\pi$)=5
$\underrightarrow{3 \text{ }4}$ $ \underleftarrow{6 \text{ }5}$ $ \underleftarrow{8 \text{ }7}$ $\underleftarrow{2\text{ } 1}$ b($\pi$)=3
$\underrightarrow{7\text{ }8}$ $\underrightarrow{5\text{ }6}$ $\underleftarrow{4\text{ }3\text{ }2\text{ } 1}$ b($\pi$)=2
$\underrightarrow{7\text{ }8}$  $ \underleftarrow{6 \text{ }5\text{ }4\text{ }3\text{ }2\text{ } 1}$ b($\pi$)=1
$\underleftarrow{8\text{ }7\text{ }6 \text{ }5\text{ }4\text{ }3\text{ }2\text{ } 1}$ b($\pi$)=0
\end{lstlisting}

This is also a possible outcome of BreakpointReversalSort\(\), and involves making different choices starting at line 3.  But the change in b($\pi$) is the same until line 5, where the original sequence I used is unable to decrease b($\pi$).\\

Is this the shortest possible number of reversals?  The smallest theoretical number of reversals $r$ for a permutation $p$ with $b$ number of breakpoints is
\begin{displaymath}
  r_{\min}(p)=\frac{b}{2}
\end{displaymath}
This holds because the maximum decrease in breakpoints per reversal is 2.  This is a theoretical minimum because it has restrictions on the permutations to which it applies.  As mentioned in the book, this can hinge on directionality of the breakpoints.  We know that there must always be one breakpoint of each direction for there to be a possibility of decreasing the number of breakpoints (and lack of such is what makes the first reversal sort above not be able to decrease the number of breakpoints from state 4 to state 5).  I have not been able to conceive of a non-recursive way of determining the actual number of breakpoints for a given permutation, given the permutation and directionality and length of its breakpoints.


%need to finish answering how to determine shortest possible
\afterpage{\clearpage}

\section{}
\paragraph{3a.} 
Figure~\ref{wlboard} shows s($i,j$) plotted for $1 \geq i,j \geq 8$.  I plotted by labeling the winning square, s($8,8$) = L because if a player 'begins' a turn on that square the game is over; the opponent has just won.  Because of this, we know that s($8,j$), s($i,8$) = W because a player beginning her turn there can move to s(8,8).  Next, we can infer that s($7,7$) = L because the only legal moves involve letting the opponent begin their turn on a W square.  This scenario is shown in Figure~\ref{lastboard}.  At this point we can notice a pattern: when $i == j$, s($i,j$) = L.  Otherwise, s($i,j$) = W because there exists some legal move from the current space to a space where $i == j$, leaving the opponent only moves where this strategy can be repeated until the endgame.  Figure~\ref{2lastboard} demonstrates this for s($7,7$).  Another way of stating this is that, if $i == j$, it will take at least two rook moves for $(i - n) == (j-n)$.  Therefore, the player beginning their turn on a square where $i == j$ will be unable to reach s($8,8$) unless her opponent makes a mistake. 

A recurrence relation for s($i,j$) and $max(i,j) \rightarrow min(i,j)$ is
\begin{displaymath}
 s(i,j) =
  \begin{cases}
  L \text{ if } i==8 \land j==8\\
  W \text{ if } \exists s(j\rightarrow8,i) = L \vee \exists s(j,i\rightarrow8) = L\\
  L \text{ if }  \nexists s(j\rightarrow8,i) = L \land \nexists s(j,i\rightarrow8) = L\\
  \end{cases}
\end{displaymath}
In this relation, s(8,8) is set to L.  All squares that allow a move onto an s(i,j)==L (i.e. $s(7,8)$ and $s(8,7)$) are then set to W.  All squares that have no L squares in their allowable field of movement are called L.  This should proceed recursively from s(8,8) to s(1,1) in a diagonal fashion.
\begin{figure}[!ht]
\def\winarea{a1-a7,b6-b1,c5-c1,d4-d1,e3-e1,f2-f1,c8-c7,d8-d6,e8-e5,f8-f4,g8-g3,h8-h2}
\chessboard[pgfstyle=text,
text=W,
border=false,
showmover=false,
label=false,
backarea=\winarea,
backfields=g1,
backfields=b8,
color=red,
pgfstyle=text,
text=L,
markfields={a8,b7,c6,d5,e4,f3,g2,h1},
markstyle=straightmove,
color=black,
markmove={a6-c6,a5-d5,a4-e4,a3-f3,a7-b7,a2-g2,g8-g2,f8-f3,e8-e4,d8-d5,c8-c6,b8-b7}]
\caption{s($i,j$) for a board of $1 \geq i,j \geq 8$.  The squares without arrows indicate a player starting from that square can win immediately by moving to s($i,j$).  The squares with arrows indicate where the player must move to force a win.}
\label{wlboard}
\end{figure}



\begin{figure}[phtb]
\def\winarea{a1-a7,b6-b1,c5-c1,d4-d1,e3-e1,f2-f1,c8-c7,d8-d6,e8-e5,f8-f4,g8-g3,h8-h2}
\chessboard[pgfstyle=text,
text=W,
border=false,
showmover=false,
label=false,
backarea=\winarea,
backfields=g1,
backfields=b8,
color=red,
pgfstyle=text,
text=L,
markfields={a8,b7,c6,d5,e4,f3,g2,h1},
markstyle=straightmove,
markmove={g2-g1,g2-h2},
color=black,
markmove={g1-h1,h2-h1}]
\caption{An example end game.  s(7,7) = L because the player starting from this square's only two legal moves set up the opponent to win, from either s($7,8$) or s($8,7$)}
\label{lastboard}
\end{figure}
\clearpage

\begin{figure}[pbth]
\def\winarea{a1-a7,b6-b1,c5-c1,d4-d1,e3-e1,f2-f1,c8-c7,d8-d6,e8-e5,f8-f4,g8-g3,h8-h2}
\chessboard[pgfstyle=text,
smallboard,
text=W,
border=false,
showmover=false,
label=false,
backarea=\winarea,
backfields=g1,
backfields=b8,
color=red,
pgfstyle=text,
text=L,
markfields={a8,b7,c6,d5,e4,f3,g2,h1},
markstyle=straightmove,
markmove={g2-g1,g2-h2,f3-f2,f3-g3,f3-f1,f3-h3},
color=black,
markmove={g1-h1,h2-h1,f1-h1,h3-h1,f2-g2,g3-g2}]
\caption{s($6,6$) = L because the all moves either allow the opponent to win (i.e. are s($8,j$) or s($i,8$)) or to move the piece to another 'L' square.  An annotation of possible moves on the full board would follow the same pattern.}
\label{2lastboard}
\end{figure}
%[markstyle=straightmove,
%markmove=a1-a3,


\paragraph{3b}Pseudocode for filling out s(i,j) recursively is shown below.\\
\lstinline{RookGame(n,m)}

\begin{lstlisting}[mathescape=true]
s= $n\times m$
for i in n to 1
	for j in m to 1
		jwin $\gets$ false
		if $i ==n \&\& j==m$
			s(i,j) $\gets$  L
		else
			for x from j to m
				if s(i,j+x)==L
					s(i,j) $\gets$ W
					jwin $\gets$ true
			if jwin==false
				for x from i to n
					if s(i+x,j)==L
						s(i,j) $\gets$ W
\end{lstlisting}

In Figure~\ref{wlboard} it's easy to see a pattern: $\begin{cases} 
   L \text{ if } i==j \\
   W
\end{cases}$  \\
This is the key to making a much faster algorithm.
\clearpage
\lstinline{FastRook(i,j)}

\begin{lstlisting}[mathescape=true]
s= $n\times m$
for i in n to 1
	for j in m to 1
		if i==j
			s(i,j) $\gets$ L
		else
			s(i,j) $\gets$ W
\end{lstlisting}

\paragraph{3c \& 3d}  The first player will always lose if the second player adopts the strategy of moving to a s($i,j$) == L, and this is the case iff $i==j$.  Because there is one and only one 'L' in each row-column pair, and rooks can travel anywhere along a row or column, it will always be possible to force a win if starting a move on a s($i,j$) = W, i.e. for $i\neq j$.  So the winning strategy is to go second in this game and always move to a s($i,j$) where $i == j $.  Eventually, the opponent will be forced to move to either s($8,j$) or s($i,8$) from which you can move to s($8,8$) and win, as shown in Figure~\ref{lastboard}.\\
 

\clearpage

\section{} The following questions will use the sequences shown in Table~\ref{4sequences}, with a score of -1.
\begin{table}[htb]
\begin{tabular}{l}
v = TACGGGTAT\\
w = GGACGTACG
\end{tabular}
\caption{Sequences $v$ and $w$ for question 4.}
\label{4sequences}
\end{table}
\paragraph{4a. - Global Alignment}  A global alignment with backtracking arrows is in Table~\ref{galigntable}.  The alignment has a score of $-1$, corresponding to a sequence also shown in Table~\ref{galigntable}.

\begin{table}[htb]
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}\hline
& T&A&C& G & G & G & T & A & T \\ \hline
G & -1 & -2 & -3 & -4 & -5 & -6 & -7 & -8 & -9 \\ \hline
G & -2$\uparrow$ & -2 & -3 & -2 & -3 & -4  & -5 & -6 & -7 \\ \hline
A & -3 & -1$\nwarrow$ & -2 & -3 & -3 & -4 & -5 & -4  & -5 \\ \hline
C & -4 & -2 & 0$\nwarrow$  & -1 & -2 & -3 & -4 & -5 & -5 \\ \hline
G & -5 & -3 & -1 & 1$\nwarrow$ & 0$\leftarrow$ & -1 $\leftarrow$& -2 & -3 & -4 \\ \hline
T & -6 & -4 & -2 & 0  & 0  & -1  & 0$\nwarrow$  &-1&-2\\ \hline
A & -7 & -5 & -3 & -1 & -1  & -1  & -1  & 1$\nwarrow$ &0\\ \hline
C & -8 & -6 & -4 & -2 & -2 & -2  & -2  & 0 $\uparrow$ & 0  \\\hline
G & -9 & -7 & -5 & -1 & -1  & -1 & -2 & -1  & -1$\nwarrow$  \\\hline
\end{tabular}
\begin{tabular}{ccccccccccccc}
v = &-&T&A&C&G&G&G&T&A&-&T\\
&X&X&|&|&|&X&X&|&|&X&X\\
w = &G&G&A&C&G-&-&-&T&A&C&G\\
\end{tabular}
\caption{A global alignment of $v$ and $w$, with a score of -1}
\label{galigntable}
\end{table}

\paragraph{4b. - Local Alignment} The optimal local alignment and dynamic programming table are shown in Table~\ref{laligntable}.  This optimal alignment has a score of 4.

%need to check: is this correct local alignment?
\begin{table}[hbt]
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}\hline
   & T & A & C & G & G & G & T & A & T \\ \hline
G &0&0&0&1&1&1&0&0&0\\ \hline
G &0&0&0&1&2&2&1&0&0\\ \hline
A &0&1&0&0&1&1&1&2&1\\ \hline
C &0&0&2&1&0&0&0&1&1\\ \hline
G &0&0&1&3&2&1&2&1&1\\ \hline
T &1$\searrow$&0&0&2&2&1&2&1&1\\ \hline
A &0&2$\searrow$&1&1&1&1&1&3&2\\ \hline
C &0&1&3$\searrow$&2&1&0&0&2&2\\ \hline
G &1&0&2&4$\searrow$&3&2&1&1&1\\ \hline
\end{tabular}\\
\begin{tabular}{ccccccccccccccccccc}
v = &&&&&&T&A&C&G&G&G&T&A&T\\
&&&&&&|&|&|&|&&&&&&&\\
w = &G&G&A&C&G&T&A&C&G&&&&&\\
\end{tabular}
\caption{A local alignment of $v$ and $w$, with score 4.}
\label{laligntable}
\end{table}


\paragraph{4c. Affine Gap Penalty}The affine gap penalty of -20 would bias the alignment away from indels.  Also, since it's more than the best possible score of a perfect alignment (10) nor generate anything greater than the worst possible alignment score, -9, in Table~\ref{galigntable}, this configuration of penalties and bonuses means that the global alignment score is simply the end-to-end alignment of each strand. as shown  in Table~\ref{galign20}.
\begin{table}[htb]
\begin{tabular}{ccccccccccccccccccc}
v = &T&A&C&G&G&G&T&A&T\\
     &X&X&X&X&|&X&X&X&X\\
w = &G&G&A&C&G&T&A&C&G\\
\end{tabular}
\caption{A global alignment of $v$ and $w$, with score -7.}
\label{galign20}
\end{table}

An Aside:
The question was about global alignments, but it's also interesting to consider local alignments.  There are no indels in the local alignment shown in Table~\ref{laligntable}, so this change in weighting would not have an effect.  As an observation, though, weight bonuses of +1 and affine gap penalties of -20 are structured so as to preclude \textit{any} affine gaps in sequences as small as those we have here.  This configuration would essentially turn the algorithm into one that searches for the longest consecutive string of matching characters.

So, the optimal local alignment remains that in Table~\ref{laligntable}, with a score of 4.
\clearpage
\section{}  
\paragraph{5a \& 5b}I cannot think of how to devise an algorithm to determine the edit distance between two strings $v$ and $w$ with time complexity of $O(sn)$ because, in the case where the edit distance is less than s, it will have to traverse a space of $n \times n$ cells, yielding a complexity of $O(n^2)$.  
Given this, it seems that we can consider 5a and 5b together. \\
 \\
 
\lstinline{LessEdit(v,w,s)}
\begin{lstlisting}[mathescape=true]
Prepend $0$ to v, w
Create Array edit, $|v| \times |w|$
for x $\gets 1$ to |v|
	edit (x,0) $\gets 0$
for x $\gets 1$ to |w|
	edit (0,x) $\gets 0$
for j $\gets 1$ to |v|
	for i $\gets 1$ to |w|
		edit(j,i) $\gets \min \begin{cases} \text{edit}(j-1,i-1) - 1 \\\text{edit}(j,i-1) - 1\\\text{edit}(j-1,i) - 1\\\text{edit}(j-1,i-1) + 1\text{    iff } v_{j-1}==w_{i-1}\end{cases}$
		if edit(j,i) $\geq$ s
			return false
return true
\end{lstlisting}
As discussed above, this algorithm has a time complexity of $O(n^2)$ or $O(nm)$, respectively.  This is because of the nested \lstinline{for} loops.
In my research into this topic it seems that Ukkonen developed an edit distance algorithm in 1983 that had a time complexity of $O(nd)$, where $d$ is the edit distance.  \footnote{http://www.csse.monash.edu.au/~lloyd/tildeAlgDS/Dynamic/Edit/}  This algorithm could almost certainly be modified to break when the parameter $d \> s$, yielding our solution. 
\end{document}